{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgllife.utils import ScaffoldSplitter,RandomSplitter\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Tuple, Dict, List, Set, Union\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from random import Random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random split\n",
    "def train_test_validation_split(df):\n",
    "    train_data, rest_data = train_test_split(df, test_size=0.2)\n",
    "    test_data, validation_data = train_test_split(rest_data, test_size=0.5)\n",
    "    return train_data.reset_index(drop=True), validation_data.reset_index(drop=True), test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaffold split\n",
    "def generate_scaffold(mol: Union[str, Chem.Mol], include_chirality: bool = False) -> str:\n",
    "    \n",
    "    mol = Chem.MolFromSmiles(mol) if type(mol) == str else mol\n",
    "    scaffold = MurckoScaffold.MurckoScaffoldSmiles(mol=mol, includeChirality=include_chirality)\n",
    "\n",
    "    return scaffold\n",
    "\n",
    "    \n",
    "def scaffold_to_smiles(mols: Union[List[str], List[Chem.Mol]],\n",
    "                       use_indices: bool = True) -> Dict[str, Union[Set[str], Set[int]]]:\n",
    "\n",
    "    scaffolds = defaultdict(set)\n",
    "    for i, mol in tqdm(enumerate(mols), total=len(mols)):\n",
    "        scaffold = generate_scaffold(mol)\n",
    "        if use_indices:\n",
    "            scaffolds[scaffold].add(i)\n",
    "        else:\n",
    "            scaffolds[scaffold].add(mol)\n",
    "\n",
    "\n",
    "    return scaffolds\n",
    "\n",
    "def scaffold_split(data: pd.DataFrame,\n",
    "                   sizes: Tuple[float, float, float] = (0.8, 0.1, 0.1),\n",
    "                   balanced: bool = True,\n",
    "                   seed: int = 2020,\n",
    "                   ) :\n",
    "\n",
    "    assert sum(sizes) == 1\n",
    "\n",
    "   \n",
    "    # Split\n",
    "    train_size, val_size, test_size = sizes[0] * len(data), sizes[1] * len(data), sizes[2] * len(data)\n",
    "    train, val, test = [], [], []\n",
    "    train_scaffold_count, val_scaffold_count, test_scaffold_count = 0, 0, 0\n",
    "\n",
    "    # Map from scaffold to index in the data\n",
    "    scaffold_to_indices = scaffold_to_smiles(data['smiles'].to_list(), use_indices=True)\n",
    "\n",
    "    # Seed randomness\n",
    "    random = Random(seed)\n",
    "\n",
    "    if balanced:  # Put stuff that's bigger than half the val/test size into train, rest just order randomly\n",
    "        index_sets = list(scaffold_to_indices.values())\n",
    "        big_index_sets = []\n",
    "        small_index_sets = []\n",
    "        for index_set in index_sets:\n",
    "            if len(index_set) > val_size / 2 or len(index_set) > test_size / 2:\n",
    "                big_index_sets.append(index_set)\n",
    "            else:\n",
    "                small_index_sets.append(index_set)\n",
    "        random.seed(seed)\n",
    "        random.shuffle(big_index_sets)\n",
    "        random.shuffle(small_index_sets)\n",
    "        index_sets = big_index_sets + small_index_sets\n",
    "    else:  # Sort from largest to smallest scaffold sets\n",
    "        index_sets = sorted(list(scaffold_to_indices.values()),\n",
    "                            key=lambda index_set: len(index_set),\n",
    "                            reverse=True)\n",
    "\n",
    "    for index_set in index_sets:\n",
    "        if len(train) + len(index_set) <= train_size:\n",
    "            train += index_set\n",
    "            train_scaffold_count += 1\n",
    "        elif len(val) + len(index_set) <= val_size:\n",
    "            val += index_set\n",
    "            val_scaffold_count += 1\n",
    "        else:\n",
    "            test += index_set\n",
    "            test_scaffold_count += 1\n",
    "    print(f'Total scaffolds = {len(scaffold_to_indices):,} | '\n",
    "                     f'train scaffolds = {train_scaffold_count:,} | '\n",
    "                     f'val scaffolds = {val_scaffold_count:,} | '\n",
    "                     f'test scaffolds = {test_scaffold_count:,}')\n",
    "    # Map from indices to data\n",
    "    train = [data.values[i] for i in train]\n",
    "    val = [data.values[i] for i in val]\n",
    "    test = [data.values[i] for i in test]\n",
    "    train1 = pd.DataFrame(train, columns=['smiles','basic_pka'])\n",
    "    val1 = pd.DataFrame(val, columns=['smiles','basic_pka'])\n",
    "    test1 = pd.DataFrame(test, columns=['smiles','basic_pka'])\n",
    "    print(f'train.shape: {train1.shape}, valid.shape: {val1.shape}, test.shape: {test1.shape}')\n",
    "    \n",
    "    assert train1.shape[0]+val1.shape[0]+test1.shape[0]==data.shape[0]\n",
    "    return train1, val1, test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logD=pd.read_csv(\"processed_chembl_29_logD(M-data).csv\")\n",
    "logp=pd.read_csv(\"logp.csv\")\n",
    "RT=pd.read_csv(\"RT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a,valid_a,test_a=scaffold_split(logD)\n",
    "train_b,valid_b,test_b=scaffold_split(logp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
